{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Mover's Distance \n",
    "## по статье Matthew J. Kusner'а \"From Word Embeddings to Document Distances\" [1]\n",
    "\n",
    "![img](https://raw.githubusercontent.com/mkusner/wmd/master/fig1.png)\n",
    "\n",
    "\n",
    "Формулировка задачи определения сходства между двумя предложениями как задачи транспортной задачи:\n",
    "\n",
    "1. Пусть $X \\in \\mathbb{R}^{d \\times n}$ – матрица эмбеддингов,  $d$ – размерность эмбеддинга, $n$ - количество слов;\n",
    "2. Вектор-документ в векторной модели: $d \\in \\mathbb{R}^n$ состоит из $c_i = \\texttt{count}(word_i, doc)$\n",
    "3. Нормированный вектор-документ: $d_i = \\frac{c_i}{\\sum_i c_i}$\n",
    "4. Расстояние между словами: $\\texttt{cost}(word_i, word_j) = ||x_i - x_j||_2$\n",
    "\n",
    "Дано два документа, $d, d'$. Пусть  $T \\in \\mathbb{R}^{n \\times n}$, $T_{ij} \\ge 0$ – матрица потока показывает расстояния от каждого слова $d$ до $d'$.\n",
    "\n",
    "Транспортная задача:\n",
    "\n",
    "$\\min_{T \\ge 0} \\sum_{i,j}^n T_{ij}\\texttt{cost}(word_i, word_j) $\n",
    "\n",
    "при условии:\n",
    "\n",
    "$\\sum_{j} T_{ij} = d_i$\n",
    "\n",
    "$\\sum_{i} T_{ij} = d'_j$.\n",
    "\n",
    "Задача решается средствами линейного программирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примеры "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "start_nb = time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем fasttext эмбеддинги Facebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ссылка на эмбеддинги: https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.ru.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/NLP/embeddings/wiki.ru.vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a190597f3667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/NLP/embeddings/wiki.ru.vec'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cell took %.2f seconds to run.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;31m# local files -- both read & write supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;31m# compression, if any, is determined by the filename extension (.gz, .bz2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfile_smart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"s3\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s3n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s3u\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mfile_smart_open\u001b[0;34m(fname, mode)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \"\"\"\n\u001b[0;32m--> 644\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompression_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/NLP/embeddings/wiki.ru.vec'"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "import os\n",
    "\n",
    "from gensim.models import *\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('/NLP/embeddings/wiki.ru.vec', binary=False)\n",
    "\n",
    "print('Cell took %.2f seconds to run.' % (time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем попарное сходство между тремя тестовыми предложениями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'Ученые обнаружили ископаемую ящерицу с парой теменных глаз'\n",
    "s2 = 'У палеогеновой ящерицы нашли вторую пару глаз'\n",
    "s3 = 'Apple через два года откажется от процессоров Intel'\n",
    "\n",
    "distance = model.wmdistance(s1, s2)\n",
    "print ('distance between s1 and s2 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s1, s3)\n",
    "print ('distance between s1 and s3 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s2, s3)\n",
    "print ('distance between s2 and s3 = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем попарное сходство между тремя тестовыми предложениями с использованием нормированных эмбеддингов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_sims(replace=True)  \n",
    "\n",
    "distance = model.wmdistance(s1, s2)\n",
    "print ('distance between s1 and s2 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s1, s3)\n",
    "print ('distance between s1 and s3 = %.4f' % distance)\n",
    "\n",
    "distance = model.wmdistance(s2, s3)\n",
    "print ('distance between s2 and s3 = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим тоже самое на корпусе твиттов [1]. \n",
    "\n",
    "Считываем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tdate</th>\n",
       "      <th>tuser</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>trep</th>\n",
       "      <th>tfav</th>\n",
       "      <th>tstcount</th>\n",
       "      <th>tfol</th>\n",
       "      <th>tfriend</th>\n",
       "      <th>listcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408906692374446080</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>pleease_shut_up</td>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7569</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408906692693221377</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>alinakirpicheva</td>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11825</td>\n",
       "      <td>59</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408906695083954177</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>EvgeshaRe</td>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1273</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408906695356973056</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>ikonnikova_21</td>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1549</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408906761416867842</td>\n",
       "      <td>1386325943</td>\n",
       "      <td>JumpyAlex</td>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       tdate            tuser  \\\n",
       "0  408906692374446080  1386325927  pleease_shut_up   \n",
       "1  408906692693221377  1386325927  alinakirpicheva   \n",
       "2  408906695083954177  1386325927        EvgeshaRe   \n",
       "3  408906695356973056  1386325927    ikonnikova_21   \n",
       "4  408906761416867842  1386325943        JumpyAlex   \n",
       "\n",
       "                                               ttext  ttype  trep  tfav  \\\n",
       "0  @first_timee хоть я и школота, но поверь, у на...      1     0     0   \n",
       "1  Да, все-таки он немного похож на него. Но мой ...      1     0     0   \n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...      1     0     1   \n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...      1     0     1   \n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...      1     0     0   \n",
       "\n",
       "   tstcount   tfol  tfriend  listcount  \n",
       "0         0   7569       62         61  \n",
       "1         0  11825       59         31  \n",
       "2         0   1273       26         27  \n",
       "3         0   1549       19         17  \n",
       "4         0    597       16         23  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/positive.csv', sep=';', header=None,  index_col = False,\n",
    "                  names = [ 'id', 'tdate', 'tuser', 'ttext', 'ttype',\n",
    "                          'trep', 'tfav', 'tstcount', 'tfol','tfriend', 'listcount'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка (приводим к нижнему регистру, удаляем стоп-слова и некириллические символы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\"[А-Яа-яё]+\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    return \" \".join(regex.findall(text))\n",
    "\n",
    "\n",
    "\n",
    "def  remove_stopwords(text, stopwords = stopwords.words('russian')):\n",
    "    try:\n",
    "        return \" \".join([token for token in text.split() if not token in stopwords])\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "raw_tweets = data.ttext.tolist()\n",
    "data.ttext = data.ttext.str.lower()\n",
    "data.ttext = data.ttext.apply(words_only)\n",
    "data.ttext = data.ttext.apply(remove_stopwords)   \n",
    "\n",
    "\n",
    "tweets = [tweet.split() for tweet in data.ttext.tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем класс для вычисления близостей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities import WmdSimilarity\n",
    "num_best = 10\n",
    "instance = WmdSimilarity(tweets, model, num_best=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем документ-запрос и предобрабатываем его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'Ученые обнаружили ископаемую ящерицу с парой теменных глаз'\n",
    "query = words_only(s1).lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поиск по запросу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = instance[query] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Query:', query)\n",
    "for i in range(10):\n",
    "    print(sims[i][0])\n",
    "    print(raw_tweets[sims[i][0]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Источники \n",
    "1. Kusner, Matt, Yu Sun, Nicholas Kolkin, and Kilian Weinberger. \"From word embeddings to document distances.\" In International Conference on Machine Learning, pp. 957-966. 2015.\n",
    "2. Ю. В. Рубцова. Построение корпуса текстов для настройки тонового классификатора // Программные продукты и системы, 2015, №1(109), –С.72-78"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
