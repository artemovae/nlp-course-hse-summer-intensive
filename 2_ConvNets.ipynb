{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Классификация текстов сверточными нейронными сетями [convolutional neural network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слой свертки\n",
    "\n",
    "#### Фильтр [filter]:\n",
    "* $w_{1,n}$ – последовательность слов, $k$  – размер окна\n",
    "* $w_i$ , $d_{emb}$ – размерность эмбеддинга слова,  $\\textbf{w}_i \\in \\mathbb{R}^{d_{emb}} $\n",
    "* $\\textbf{x}_i = [\\textbf{w}_{i}, \\textbf{w}_{i+1}, \\ldots, \\textbf{w}_{i+k-1}]$, $\\textbf{x}_i \\in \\mathbb{R}^{k d_{emb}}$\n",
    "\n",
    "Фильтр: $p_i = g(\\textbf{x}_i  u)$, $p_i \\in \\mathbb{R}$, $u \\in \\mathbb{R}^{k d_{emb}}$\n",
    "\n",
    "\n",
    "![title](img/cnn1.png)\n",
    "\n",
    "\n",
    "Преобразуем каждое входное окно, но пока размерность входа не уменьшается!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Слой субдискретизации (пулинга, [pooling])\n",
    "\n",
    "* $h_i$ – выходные значения фильтра\n",
    "\n",
    "$\\max$-пулинг:\t$c = \\max_i h_i$\n",
    "\n",
    "\n",
    "![title](img/cnn2.png)\n",
    "\n",
    "* Выбираем самый важный признак из полученных на предыдущем шаге \n",
    "* Можем использовать и $\\min$, и усреднение\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификатор на основе сверточной сети\n",
    "\n",
    "* $y \\in [0,1] $ - истинные значения\n",
    "* $\\widehat{y} = c$ - предсказанные значения\n",
    "\n",
    "![title](img/cnn3.png)\n",
    "\n",
    "Для обучения сверточной сети можно использовать обычный алгоритм распространения ошибки\n",
    "\n",
    "Одномерные фильтры – это сильное ограничение. Что делать, если $c=0.5$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Многомерные фильтры\n",
    "\n",
    "Используем $\\textit{l}$ разных фильтров: $u_{1}, \\ldots, u_{\\textit{l}}$: \n",
    "\n",
    "$\\textbf{x}_i = [\\textbf{w}_{i}, \\textbf{w}_{i+1}, \\ldots, \\textbf{w}_{i+k-1}]$\n",
    "\n",
    "$\\textbf{p}_i = g(\\textbf{x}_i \\cdot  U+b)$\n",
    "\n",
    "$\\textbf{p}_i \\in \\mathbb{R}^{\\textit{l}} $, $\\textbf{x}_i \\in \\mathbb{R}^{k d_{emb}}$, $U \\in \\mathbb{R}^{k d_{emb} \\times \\textit{l}}$, $b \\in \\mathbb{R}^{\\textit{l}} $\n",
    "\n",
    "![title](img/cnn4.png)\n",
    "\n",
    "\n",
    "$\\max$-пулинг:\t$c_j = \\max_i h_{i,j}, j \\in [0,\\textit{l}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг окна \n",
    "Можно использовать непересекающиеся окна, чтобы уменьшить объем вычисления\n",
    "\n",
    "![title](img/cnn5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как выбирать вектора слов? \n",
    "* Случайная инициализация (если нет обученных моделей word2vec, GloVe)\n",
    "* word2vec, GloVe без обновления\n",
    "* word2vec, GloVe c обновлением на каждой эпохе (увеличивается количество параметров!)\n",
    "* Несколько каналов: копируем два входа и\n",
    "    * на один подаем word2vec и не обновляем эти входы во время обучения, на второй подаем word2vec и обновляем эти входы во время обучения\n",
    "    * на один вход подаем word2vec, на второй – GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Embedding, Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Masking\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random.seed(1228)\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.layers import Convolution1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import  concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train examples 151978\n",
      "total test examples 74856\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "\n",
    "regex = re.compile(\"[А-Яа-я:=!\\)\\()A-z\\_\\%/|]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "\n",
    "df_neg = pd.read_csv(\"../data/negative.csv\", sep=';', header = None, usecols = [3])\n",
    "df_pos = pd.read_csv(\"../data/positive.csv\", sep=';', header = None, usecols = [3])\n",
    "df_neg['sent'] = 'neg'\n",
    "df_pos['sent'] = 'pos'\n",
    "df = pd.concat([df_neg, df_pos])\n",
    "df.columns = ['text', 'sent']\n",
    "df.text = df.text.apply(words_only)\n",
    "df.text = df.text.apply(lemmatize)\n",
    "\n",
    "\n",
    "X = df.text.tolist()\n",
    "y = df.sent.tolist()\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "X_text_train, X_text_test, y_train, y_test = train_test_split(X,y, test_size=0.33)\n",
    "print (\"total train examples %s\" % len(y_train))\n",
    "print (\"total test examples %s\" % len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "TEXT_LENGTH = 10\n",
    "VOCABULARY_SIZE = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "DIMS = 250\n",
    "MAX_FEATURES = 5000\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "filter_length = 3\n",
    "\n",
    "nb_filter = 50\n",
    "\n",
    "hidden_dims = 100\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x11cb94b70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_text_train)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(X_text_train)\n",
    "X_train = pad_sequences(sequences, maxlen=TEXT_LENGTH)\n",
    "sequences = tokenizer.texts_to_sequences(X_text_test)\n",
    "X_test = pad_sequences(sequences, maxlen=TEXT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   70,   150, 53079,     1,  7628,  5003,   192,    77,     2,\n",
       "         249], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(['pos', 'neg'])\n",
    "y_train_cat = np_utils.to_categorical(le.transform(y_train), 2)\n",
    "y_test_cat = np_utils.to_categorical(le.transform(y_test), 2)\n",
    "\n",
    "print(y_train_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 30s, sys: 6.88 s, total: 2min 37s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "emb_path = '/NLP/embeddings/wiki.ru.vec'\n",
    "\n",
    "words = []\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(emb_path, encoding = 'utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    if len(values) == 301:\n",
    "        word = values[0]\n",
    "        words.append(word)\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1775997\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158234"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158235, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_input = Input(shape=(TEXT_LENGTH,), dtype='int32', name='words_input')\n",
    "\n",
    "\n",
    "\n",
    "#Our word embedding layer\n",
    "wordsEmbeddingLayer = Embedding(len(word_index),\n",
    "                    300,                                     \n",
    "#                     weights=[embedding_matrix],\n",
    "                    trainable=True)\n",
    "\n",
    "\n",
    "words = wordsEmbeddingLayer(words_input)\n",
    "\n",
    "\n",
    "words_conv = Convolution1D(filters=nb_filter,\n",
    "                            kernel_size=filter_length,\n",
    "                            padding='same',\n",
    "                            activation='relu',\n",
    "                            strides=1)(words)\n",
    "\n",
    "words_conv = GlobalMaxPooling1D()(words_conv)  \n",
    "\n",
    "output = words_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136780 samples, validate on 15198 samples\n",
      "Epoch 1/20\n",
      "136780/136780 [==============================] - 30s 216us/step - loss: 0.6395 - acc: 0.6706 - val_loss: 0.5622 - val_acc: 0.7110\n",
      "Epoch 2/20\n",
      "136780/136780 [==============================] - 28s 202us/step - loss: 0.5677 - acc: 0.7062 - val_loss: 0.5492 - val_acc: 0.7152\n",
      "Epoch 3/20\n",
      "136780/136780 [==============================] - 29s 213us/step - loss: 0.5552 - acc: 0.7165 - val_loss: 0.5427 - val_acc: 0.7246\n",
      "Epoch 4/20\n",
      "136780/136780 [==============================] - 28s 203us/step - loss: 0.5453 - acc: 0.7250 - val_loss: 0.5406 - val_acc: 0.7246\n",
      "Epoch 5/20\n",
      "136780/136780 [==============================] - 27s 198us/step - loss: 0.5398 - acc: 0.7284 - val_loss: 0.5328 - val_acc: 0.7344\n",
      "Epoch 6/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.5332 - acc: 0.7341 - val_loss: 0.5309 - val_acc: 0.7333\n",
      "Epoch 7/20\n",
      "136780/136780 [==============================] - 28s 203us/step - loss: 0.5289 - acc: 0.7383 - val_loss: 0.5316 - val_acc: 0.7322\n",
      "Epoch 8/20\n",
      "136780/136780 [==============================] - 27s 198us/step - loss: 0.5256 - acc: 0.7424 - val_loss: 0.5252 - val_acc: 0.7386\n",
      "Epoch 9/20\n",
      "136780/136780 [==============================] - 27s 198us/step - loss: 0.5210 - acc: 0.7446 - val_loss: 0.5267 - val_acc: 0.7391\n",
      "Epoch 10/20\n",
      "136780/136780 [==============================] - 27s 199us/step - loss: 0.5174 - acc: 0.7469 - val_loss: 0.5227 - val_acc: 0.7394\n",
      "Epoch 11/20\n",
      "136780/136780 [==============================] - 27s 199us/step - loss: 0.5156 - acc: 0.7493 - val_loss: 0.5227 - val_acc: 0.7435\n",
      "Epoch 12/20\n",
      "136780/136780 [==============================] - 28s 207us/step - loss: 0.5119 - acc: 0.7517 - val_loss: 0.5275 - val_acc: 0.7373\n",
      "Epoch 13/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.5088 - acc: 0.7540 - val_loss: 0.5229 - val_acc: 0.7431\n",
      "Epoch 14/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.5064 - acc: 0.7564 - val_loss: 0.5229 - val_acc: 0.7421\n",
      "Epoch 15/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.5031 - acc: 0.7585 - val_loss: 0.5224 - val_acc: 0.7413\n",
      "Epoch 16/20\n",
      "136780/136780 [==============================] - 27s 201us/step - loss: 0.5023 - acc: 0.7593 - val_loss: 0.5194 - val_acc: 0.7448\n",
      "Epoch 17/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.4979 - acc: 0.7626 - val_loss: 0.5187 - val_acc: 0.7452\n",
      "Epoch 18/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.4978 - acc: 0.7626 - val_loss: 0.5182 - val_acc: 0.7435\n",
      "Epoch 19/20\n",
      "136780/136780 [==============================] - 27s 198us/step - loss: 0.4934 - acc: 0.7666 - val_loss: 0.5235 - val_acc: 0.7437\n",
      "Epoch 20/20\n",
      "136780/136780 [==============================] - 27s 198us/step - loss: 0.4933 - acc: 0.7659 - val_loss: 0.5189 - val_acc: 0.7452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11cb94e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_cat, epochs=nb_epoch, batch_size=batch_size,  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:   0.75\n",
      "Recall:   0.75\n",
      "F1-measure:   0.75\n",
      "Accuracy:   0.75\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.75      0.74      0.74     36898\n",
      "        pos       0.75      0.76      0.75     37958\n",
      "\n",
      "avg / total       0.75      0.75      0.75     74856\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16d07deb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pred.argmax(axis=-1)\n",
    "y_pred = le.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, y_pred, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, y_pred, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, y_pred, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "sns.heatmap(data=confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cbar=False, xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "\n",
    "Реализуйте сверточную сеть с несколькими каналами с фильтрами разной размерности (т.е. с разными входными свертками ```words_conv```). \n",
    "\n",
    "Размеры фильтров: ```filter_lengths = [1,2,3]```.\n",
    "\n",
    "Для конкатенации сверток используйте ```concatenate```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n'*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Решение\n",
    "\n",
    "words_input = Input(shape=(TEXT_LENGTH,), dtype='int32', name='words_input')\n",
    "\n",
    "wordsEmbeddingLayer = Embedding(embedding_matrix.shape[0],\n",
    "                    embedding_matrix.shape[1],                                     \n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False)\n",
    "\n",
    "words = wordsEmbeddingLayer(words_input)\n",
    "\n",
    "words_convolutions = []\n",
    "for filter_length in [1,2,3]:\n",
    "    words_conv = Convolution1D(filters=nb_filter,\n",
    "                            kernel_size=filter_length,\n",
    "                            padding='same',\n",
    "                            activation='relu',\n",
    "                            strides=1)(words)\n",
    "                            \n",
    "    words_conv = GlobalMaxPooling1D()(words_conv)      \n",
    "    \n",
    "    words_convolutions.append(words_conv)  \n",
    "\n",
    "output = concatenate(words_convolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_input (InputLayer)        (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 10, 300)      47470500    words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 10, 50)       15050       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 10, 50)       30050       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 10, 50)       45050       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 50)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 50)           0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 50)           0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 150)          0           global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "                                                                 global_max_pooling1d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 150)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          15100       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            202         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,575,952\n",
      "Trainable params: 105,452\n",
      "Non-trainable params: 47,470,500\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output = Dropout(0.5)(output)\n",
    "output = Dense(hidden_dims, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.01))(output)\n",
    "output = Dropout(0.25)(output)\n",
    "output = Dense(2, activation='softmax',  kernel_regularizer=keras.regularizers.l2(0.01))(output)\n",
    "\n",
    "model = Model(inputs=[words_input], outputs=[output])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
