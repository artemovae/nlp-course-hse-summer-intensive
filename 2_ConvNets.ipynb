{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Классификация текстов сверточными нейронными сетями [convolutional neural network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Слой свертки\n",
    "\n",
    "#### Фильтр [filter]:\n",
    "* $w_{1,n}$ – последовательность слов, $k$  – размер окна\n",
    "* $w_i$ , $d_{emb}$ – размерность эмбеддинга слова,  $\\textbf{w}_i \\in \\mathbb{R}^{d_{emb}} $\n",
    "* $\\textbf{x}_i = [\\textbf{w}_{i}, \\textbf{w}_{i+1}, \\ldots, \\textbf{w}_{i+k-1}]$, $\\textbf{x}_i \\in \\mathbb{R}^{k d_{emb}}$\n",
    "\n",
    "Фильтр: $p_i = g(\\textbf{x}_i  u)$, $p_i \\in \\mathbb{R}$, $u \\in \\mathbb{R}^{k d_{emb}}$\n",
    "\n",
    "\n",
    "![title](img/cnn1.png)\n",
    "\n",
    "\n",
    "Преобразуем каждое входное окно, но пока размерность входа не уменьшается!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Слой субдискретизации (пулинга, [pooling])\n",
    "\n",
    "* $h_i$ – выходные значения фильтра\n",
    "\n",
    "$\\max$-пулинг:\t$c = \\max_i h_i$\n",
    "\n",
    "\n",
    "![title](img/cnn2.png)\n",
    "\n",
    "* Выбираем самый важный признак из полученных на предыдущем шаге \n",
    "* Можем использовать и $\\min$, и усреднение\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификатор на основе сверточной сети\n",
    "\n",
    "* $y \\in [0,1] $ - истинные значения\n",
    "* $\\widehat{y} = c$ - предсказанные значения\n",
    "\n",
    "![title](img/cnn3.png)\n",
    "\n",
    "Для обучения сверточной сети можно использовать обычный алгоритм распространения ошибки\n",
    "\n",
    "Одномерные фильтры – это сильное ограничение. Что делать, если $c=0.5$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Многомерные фильтры\n",
    "\n",
    "Используем $\\textit{l}$ разных фильтров: $u_{1}, \\ldots, u_{\\textit{l}}$: \n",
    "\n",
    "$\\textbf{x}_i = [\\textbf{w}_{i}, \\textbf{w}_{i+1}, \\ldots, \\textbf{w}_{i+k-1}]$\n",
    "\n",
    "$\\textbf{p}_i = g(\\textbf{x}_i \\cdot  U+b)$\n",
    "\n",
    "$\\textbf{p}_i \\in \\mathbb{R}^{\\textit{l}} $, $\\textbf{x}_i \\in \\mathbb{R}^{k d_{emb}}$, $U \\in \\mathbb{R}^{k d_{emb} \\times \\textit{l}}$, $b \\in \\mathbb{R}^{\\textit{l}} $\n",
    "\n",
    "![title](img/cnn4.png)\n",
    "\n",
    "\n",
    "$\\max$-пулинг:\t$c_j = \\max_i h_{i,j}, j \\in [0,\\textit{l}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Шаг окна \n",
    "Можно использовать непересекающиеся окна, чтобы уменьшить объем вычисления\n",
    "\n",
    "![title](img/cnn5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как выбирать вектора слов? \n",
    "* Случайная инициализация (если нет обученных моделей word2vec, GloVe)\n",
    "* word2vec, GloVe без обновления\n",
    "* word2vec, GloVe c обновлением на каждой эпохе (увеличивается количество параметров!)\n",
    "* Несколько каналов: копируем два входа и\n",
    "    * на один подаем word2vec и не обновляем эти входы во время обучения, на второй подаем word2vec и обновляем эти входы во время обучения\n",
    "    * на один вход подаем word2vec, на второй – GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cnn7.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Embedding, Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Masking\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random.seed(1228)\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.layers import Convolution1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import  concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total train examples 151978\n",
      "total test examples 74856\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "\n",
    "regex = re.compile(\"[А-Яа-я:=!\\)\\()A-z\\_\\%/|]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def lemmatize(text, mystem=m):\n",
    "    try:\n",
    "        return \"\".join(m.lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "\n",
    "df_neg = pd.read_csv(\"data/negative.csv\", sep=';', header = None, usecols = [3])\n",
    "df_pos = pd.read_csv(\"data/positive.csv\", sep=';', header = None, usecols = [3])\n",
    "df_neg['sent'] = 'neg'\n",
    "df_pos['sent'] = 'pos'\n",
    "df = pd.concat([df_neg, df_pos])\n",
    "df.columns = ['text', 'sent']\n",
    "df.text = df.text.apply(words_only)\n",
    "df.text = df.text.apply(lemmatize)\n",
    "\n",
    "\n",
    "X = df.text.tolist()\n",
    "y = df.sent.tolist()\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "X_text_train, X_text_test, y_train, y_test = train_test_split(X,y, test_size=0.33)\n",
    "print (\"total train examples %s\" % len(y_train))\n",
    "print (\"total test examples %s\" % len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "TEXT_LENGTH = 10\n",
    "VOCABULARY_SIZE = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "DIMS = 250\n",
    "MAX_FEATURES = 5000\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "filter_length = 3\n",
    "\n",
    "nb_filter = 50\n",
    "\n",
    "hidden_dims = 100\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x1216d4828>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_text_train)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(X_text_train)\n",
    "X_train = pad_sequences(sequences, maxlen=TEXT_LENGTH)\n",
    "sequences = tokenizer.texts_to_sequences(X_text_test)\n",
    "X_test = pad_sequences(sequences, maxlen=TEXT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 384,   49, 1983,    4, 6596,  329,  419,    7,  137,  455],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(['pos', 'neg'])\n",
    "y_train_cat = np_utils.to_categorical(le.transform(y_train), 2)\n",
    "y_test_cat = np_utils.to_categorical(le.transform(y_test), 2)\n",
    "\n",
    "print(y_train_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 3s, sys: 35.6 s, total: 4min 39s\n",
      "Wall time: 9min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "emb_path = '/NLP/embeddings/wiki.ru.vec'\n",
    "\n",
    "words = []\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(emb_path, encoding = 'utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    if len(values) == 301:\n",
    "        word = values[0]\n",
    "        words.append(word)\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1775997\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158282"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158283, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136780 samples, validate on 15198 samples\n",
      "Epoch 1/20\n",
      "136780/136780 [==============================] - 27s 198us/step - loss: 0.5844 - acc: 0.6766 - val_loss: 0.5548 - val_acc: 0.7031\n",
      "Epoch 2/20\n",
      "136780/136780 [==============================] - 27s 195us/step - loss: 0.5442 - acc: 0.7112 - val_loss: 0.5337 - val_acc: 0.7159\n",
      "Epoch 3/20\n",
      "136780/136780 [==============================] - 26s 191us/step - loss: 0.5220 - acc: 0.7280 - val_loss: 0.5276 - val_acc: 0.7233\n",
      "Epoch 4/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.5024 - acc: 0.7419 - val_loss: 0.5293 - val_acc: 0.7256\n",
      "Epoch 5/20\n",
      "136780/136780 [==============================] - 28s 206us/step - loss: 0.4815 - acc: 0.7565 - val_loss: 0.5307 - val_acc: 0.7260\n",
      "Epoch 6/20\n",
      "136780/136780 [==============================] - 28s 202us/step - loss: 0.4606 - acc: 0.7710 - val_loss: 0.5263 - val_acc: 0.7283\n",
      "Epoch 7/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.4406 - acc: 0.7846 - val_loss: 0.5369 - val_acc: 0.7293\n",
      "Epoch 8/20\n",
      "136780/136780 [==============================] - 27s 201us/step - loss: 0.4204 - acc: 0.7958 - val_loss: 0.5476 - val_acc: 0.7306\n",
      "Epoch 9/20\n",
      "136780/136780 [==============================] - 29s 215us/step - loss: 0.4028 - acc: 0.8076 - val_loss: 0.5598 - val_acc: 0.7250\n",
      "Epoch 10/20\n",
      "136780/136780 [==============================] - 27s 199us/step - loss: 0.3852 - acc: 0.8163 - val_loss: 0.6071 - val_acc: 0.7261\n",
      "Epoch 11/20\n",
      "136780/136780 [==============================] - 27s 199us/step - loss: 0.3734 - acc: 0.8225 - val_loss: 0.5872 - val_acc: 0.7246\n",
      "Epoch 12/20\n",
      "136780/136780 [==============================] - 28s 201us/step - loss: 0.3555 - acc: 0.8337 - val_loss: 0.5958 - val_acc: 0.7257\n",
      "Epoch 13/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.3439 - acc: 0.8394 - val_loss: 0.6203 - val_acc: 0.7225\n",
      "Epoch 14/20\n",
      "136780/136780 [==============================] - 27s 196us/step - loss: 0.3317 - acc: 0.8462 - val_loss: 0.6455 - val_acc: 0.7265\n",
      "Epoch 15/20\n",
      "136780/136780 [==============================] - 27s 196us/step - loss: 0.3218 - acc: 0.8516 - val_loss: 0.6641 - val_acc: 0.7134\n",
      "Epoch 16/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.3124 - acc: 0.8568 - val_loss: 0.6433 - val_acc: 0.7195\n",
      "Epoch 17/20\n",
      "136780/136780 [==============================] - 29s 210us/step - loss: 0.3015 - acc: 0.8629 - val_loss: 0.6545 - val_acc: 0.7171\n",
      "Epoch 18/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.2923 - acc: 0.8677 - val_loss: 0.7417 - val_acc: 0.7199\n",
      "Epoch 19/20\n",
      "136780/136780 [==============================] - 27s 200us/step - loss: 0.2853 - acc: 0.8711 - val_loss: 0.7306 - val_acc: 0.7150\n",
      "Epoch 20/20\n",
      "136780/136780 [==============================] - 29s 210us/step - loss: 0.2769 - acc: 0.8751 - val_loss: 0.7688 - val_acc: 0.7139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2195ce860>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1,\n",
    "                            300,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=TEXT_LENGTH,\n",
    "                            trainable=False))\n",
    "\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, input_shape=(MAX_FEATURES,), activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train_cat, epochs=nb_epoch, batch_size=batch_size,  validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:   0.72\n",
      "Recall:   0.72\n",
      "F1-measure:   0.71\n",
      "Accuracy:   0.72\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.68      0.80      0.73     36884\n",
      "        pos       0.76      0.64      0.70     37972\n",
      "\n",
      "avg / total       0.72      0.72      0.71     74856\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEICAYAAACpqsStAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAFwxJREFUeJzt3XecVNXdx/HPD3YpCyJFLBgVwULEiFGDscQuakRFE0usUfNobIkxmCK2KBpjiyUWbNEoiJqiiTGJeWKKRo0PlkhQ1CCiiChFOtvP88cM64ICs8iynOXzfr3mxdx7z9z7O3D5zpkzZyFSSkiS8tSmpQuQJK04Q1ySMmaIS1LGDHFJypghLkkZM8QlKWOGuFYrEdExIn4XEbMj4qFPcZ5jIuLxlVlbS4mIL0XEay1dh1ZP4TpxrYiIOBo4B+gHzAVeAi5LKT31Kc97HHAWsHNKqfZTF7qai4gEbJ5S+m9L16I8ORJXk0XEOcB1wOXAesDGwM3AISvh9JsAr68JAV6KiChr6Rq0mksp+fBR8gNYG5gHHL6MNu0phPyU4uM6oH3x2B7AZOC7wAfAe8CJxWM/AqqBmuI1TgYuBu5rdO7eQALKittfB96k8GlgInBMo/1PNXrdzsD/AbOLv+7c6NjfgEuBfxbP8ziwzlL6tqj+7zWqfwjwZeB1YCZwXqP2A4FngFnFtj8D2hWP/aPYl/nF/h7Z6PzfB6YC9y7aV3xN3+I1titu9wKmAXu09L3ho2UejsTVVDsBHYDfLKPNMOCLwLbAAApBdn6j4+tTeDPYkEJQ3xQR3VJKF1EY3T+QUuqcUrpzWYVERCfgBuCAlNJaFIL6pU9o1x34fbFtD+Ba4PcR0aNRs6OBE4F1gXbA0GVcen0KvwcbAhcCtwPHAtsDXwIuiIhNi23rgO8A61D4vdsbOB0gpbRbsc2AYn8faHT+7hQ+lZzS+MIppQkUAv6+iKgAfg7ck1L62zLqVStmiKupegDT07KnO44BLkkpfZBSmkZhhH1co+M1xeM1KaXHKIxCt1zBeuqBrSOiY0rpvZTSuE9ocyDwRkrp3pRSbUrpfmA8cFCjNj9PKb2eUloIPEjhDWhpaijM/9cAoykE9PUppbnF679C4c2LlNLzKaVni9d9CxgB7F5Cny5KKVUV61lMSul24L/Av4ANKLxpag1liKupZgDrLGeuthcwqdH2pOK+hnMs8SawAOjc1EJSSvMpTEF8E3gvIn4fEf1KqGdRTRs22p7ahHpmpJTqis8Xhez7jY4vXPT6iNgiIh6NiKkRMYfCJ411lnFugGkppcrltLkd2Bq4MaVUtZy2asUMcTXVM0AVhXngpZlCYSpgkY2L+1bEfKCi0fb6jQ+mlP6UUtqXwoh0PIVwW149i2p6dwVraopbKNS1eUqpC3AeEMt5zTKXjEVEZwrfM9wJXFycLtIayhBXk6SUZlOYB74pIoZEREVElEfEARFxZbHZ/cD5EdEzItYptr9vBS/5ErBbRGwcEWsDP1x0ICLWi4hDinPjVRSmZeo/4RyPAVtExNERURYRRwJbAY+uYE1NsRYwB5hX/JRw2hLH3wf6NPGc1wNjUkrfoDDXf+unrlLZMsTVZCmlayisET+fwsqId4AzgYeLTYYDY4CXgbHAC8V9K3KtPwMPFM/1PIsHb5tiHVMorNjYnY+HJCmlGcBgCitiZlBYWTI4pTR9RWpqoqEUvjSdS+FTwgNLHL8YuCciZkXEEcs7WUQcAuzPR/08B9guIo5ZaRUrK/6wjyRlzJG4JGXMEJekjBnikpQxQ1ySMtbs/7hOzfQ3/eZUq6WOvb7U0iVIS1Vb/e7yfp4AcCQuSVkzxCUpY4a4JGXMEJekjBnikpQxQ1ySMmaIS1LGDHFJypghLkkZM8QlKWOGuCRlzBCXpIwZ4pKUMUNckjJmiEtSxgxxScqYIS5JGTPEJSljhrgkZcwQl6SMGeKSlDFDXJIyZohLUsYMcUnKmCEuSRkzxCUpY4a4JGXMEJekjBnikpQxQ1ySMmaIS1LGDHFJypghLkkZM8QlKWOGuCRlzBCXpIwZ4pKUMUNckjJmiEtSxgxxScqYIS5JGTPEJSljhrgkZcwQl6SMGeKSlDFDXJIyZohLUsYMcUnKmCEuSRkzxCUpY2UtXcCa6L33p3HepVcz48MPCYKvHnIAxx0xhPFvvMmlV93IgoWV9NpgXX5y0ffo3KkTY195jYt/cgMAicTpJx3DPrvvQlVVNSeccS7VNTXU1dax7567cuY3jgNg2PBrGPPSWDp36gTAZcPOod8WfVusz8rPFlv0ZdTIWxq2+2y6MRf/6Gq6du3CyScdzbTpMwG44IIr+MMfn2hot9FGvRj7779xyaXXcO1PRwBw1pknc/LJRxMR3HnnKG648Y5V25lWLFJKzXqBmulvNu8FMjRt+kymzZjJVltuxvz5Czji5G9xw48v4Lzh1zD0zG/whc9vw68f/RPvTnmfs045noWVlZSXlVNW1pZp02fylRNO54lHRtK2bRsWLqykoqIjNbW1HH/aUH7w7VMZsPVnGTb8GnbfZSCD9vxSS3d3tdWxl783pWrTpg1vv/U8O+86mK+fcCTz5s1vCOglPTD6NlJKPPfcC1z70xH0778lI++7mZ12PpDq6hoee3Qkp5/5AyZMeGvVdiIztdXvRintnE5pAT3X6c5WW24GQKdOFfTZZCPenzaDSe+8yw7bfg6Anb6wHX/++1MAdOzQgbKytgBUVVdDFP5sI4KKio4A1NbWUltbS0RJf+5Sk+y91668+eYk3n773WW2O/jg/Xhr4tu88sprDfv69duc5557kYULK6mrq+MfTz7LoUMOaO6S1xglhXhEzI2IOUs83omI30REn+YusjV79733efWNCWzTf0v6broJTzz5DACP//VJpr4/vaHdy+PGc8gxp3Lo8adx4blnNoR6XV0dXznhDHYb/DV2+sLn2aZ/v4bX3DDiHg49/jR+cv0IqqurV23H1KocccQhjH7g4Ybt0087kRee/zO333YNXbuuDRQGJN8begaXDL92sdeOGzeeXXfdke7du9GxYwcO2H8vPvOZXqu0/tas1JH4dcC5wIbAZ4ChwChgNHDXko0j4pSIGBMRY+74xf0rq9ZWZ8GChXxn2HC+/61T6dypE5ee9x1G//pRjjjpLOYvWEh5+UdfWWzTvx+PjBzB6Duu5457H6SqqhDKbdu25Vf33MRffnMvY195nTfefAuAs795Ir+7/3YeuON6Zs+Zy533PdQSXVQrUF5ezkGDB/HLXz0KwK0jfsEW/XZm+x0GMXXqB1x15YUAXHTBd7nuhtuZP3/BYq8fP/6/XHXVTfzhsVE89uhIXvr3OOrq6ld5P1qrUr/YPDilNKDR9m0R8VJK6fsRcd6SjVNKtwG3gXPiS1NTW8vZw4Zz4KA92XePXQDos8lG3H7d5QC89fZk/vH0cx97Xd/eG1PRsSNvvPkWW392i4b9XdbqzMDttuGpZ8eweZ/e9FynOwDt2rVjyIGDuPv+X62CXqk12n//PXnxxbF88EHhk+GiXwHuuHMkjzx8DwADB36eww47kCsuH0bXrl2or6+nsrKKm2+5m5/fPZqf3z0agOGX/oDJk99b9R1ppUoN8QURcQTwy+L2V4HK4nNDuolSSlz44+vos8lGnHDUYQ37Z3w4ix7dulJfX8+Ie0ZzxJAvAzB5ylTWX7cnZWVtmTL1fSZOeocNN1iPmR/OoqysjC5rdaayqopn/u9FTjr2cKDw5WnPdbqTUuKJfzzN5n02aZG+Kn9HHTlksamU9ddfl6lTPwBgyCEHMG5cYf57j70+upcvvOAc5s2bz8233A1Az549mDZtBhtt1IshQw5gl10PWnUdaOVKDfFjgOuBmymE9rPAsRHRETizmWprtV58eRy/++Nf2Lxvb75ywhkAfPvUE5g0eQqjf134yLrP7jtz6IGDAHjh5XHcee+DlJWV0aZNcP7QM+jWdW1e++9Ehg2/mrr6elJ9Yr+9vsQeu+wIwPd/dCUfzppNSoktN+/DReee1TKdVdYqKjqyz967cdrp32/Yd8WPz2fAgK1IKTFp0uTFji3NQw/cTvce3aipqeVb3xrG7NlzmrPsNYpLDLXGcomhVmcrdYlhRGwREX+JiP8Ut7eJiPM/TYGSpE+v1NUptwM/BGoAUkovA0c1V1GSpNKUGuIVKaUll0rUruxiJElNU2qIT4+IvhRXokTEVwHXCElSCyt1dcoZFNZ994uId4GJFFasSJJaUKkh/i7wc+CvQHdgDnACcEkz1SVJKkGpIf4IMAt4AZjSfOVIkpqi1BD/TEpp/2atRJLUZKV+sfl0RHyuWSuRJDVZqSPxXYGvR8REoAoIIKWUtmm2yiRJy1VqiPsvuEvSaqikEE8pTWruQiRJTed/zyZJGTPEJSljhrgkZcwQl6SMGeKSlDFDXJIyZohLUsYMcUnKmCEuSRkzxCUpY4a4JGXMEJekjBnikpQxQ1ySMmaIS1LGDHFJypghLkkZM8QlKWOGuCRlzBCXpIwZ4pKUMUNckjJmiEtSxgxxScqYIS5JGTPEJSljhrgkZcwQl6SMGeKSlDFDXJIyZohLUsYMcUnKmCEuSRkzxCUpY4a4JGXMEJekjBnikpSxsua+wNAdzmvuS0grZM6Vg1u6BOlTcyQuSRkzxCUpY4a4JGXMEJekjBnikpQxQ1ySMmaIS1LGDHFJypghLkkZM8QlKWOGuCRlzBCXpIwZ4pKUMUNckjJmiEtSxgxxScqYIS5JGTPEJSljhrgkZcwQl6SMGeKSlDFDXJIyZohLUsYMcUnKmCEuSRkzxCUpY4a4JGXMEJekjBnikpQxQ1ySMmaIS1LGDHFJypghLkkZM8QlKWOGuCRlzBCXpIwZ4pKUMUNckjJmiEtSxgxxScqYIS5JGTPEJSljhrgkZcwQl6SMGeKSlDFDXJIyZohLUsYMcUnKmCEuSRkra+kC1kRfu/JU+u+1HfNmzOGK/c4F4MvnHMHn9t2e+pSYN30OI4fewpwPPmSvUwaz/ZBdAWjbti3rbbYhw7b7HxbMnv+J5wHo9dmNOeKyb9C+ogMzJ0/jF2f/jKp5C1ukr8pLdO5Gu/1OJCrWAqB27JPUvvREw/Gy7fah3W6Hs+DWc6ByPm23HEj5DvtBBKm6kuonRpGmTwagw0mXQXUVpHpSfT1V918OQPlOB9O2zwAgkRbMpfrxu0nzZ6/yvrYWkVJq1gt8u/dRzXuBDPUd2I+q+ZUce+0ZDeHbvnPHhqDd7ev7s/7mG/LgsDsXe13/vbdjj5O/zE1HD1/qeQC++8hlPHz5fUz416vsePge9NhoXR679sFV1Lt8/PjstVu6hNVPRRei09qkae9AeXs6HD2Mqt/dQpr5XiHg9z2O6LY+laMug8r5tNmgD/Uzp0LVAtr07k/5Fw+iavQVQCHEK0ddDpXzF79Guw5QXQlA2bZ7Et03oOaJUau6p6u9irNHRCntnE5pAROeG8+C2Yvf2I1Hyu0q2vNJ763bH7wLL/z26WWeB6Dnphsw4V+vAvDaU2MZcMDAlVS5Wr0FcwoBDlBTRf3M94jOXQEo3/1wqp/8NfDRzVn/3ptQtaD4fGJD22UqBnjhpO1XVuVrLKdTViMHDj2SLxy2G5VzF3Dj1y5Z7Fh5h3b0230Av7zwruWeZ+obk/ncoB0Y+/gYtv3yjnTdoEdzlaxWLLr0oE3PjamfOpG2fQaQ5s1qmCr5JGX9d6H+rXEf7UjQ4bCzISVqxj5J3X+ebDhUvvMhtP3sF6FqIZW/urY5u9HqlTQSj4grI6JLRJRHxF8iYlpEHLuM9qdExJiIGPOfuRNWXrWt3O+vfoCLdz6DMY88xW4n7LfYsa332Z6JY177xJH3kkZ971Z2PXYQQ393OR06d6Supra5SlZrVd6e9geeSs3fH4T6OsoGHkDNM79davM2n9mCsq13ofqpXzfsq3rwKipHXUblwzdSPmB32my4ecOxmqcfofLOH1L72nOUD9izWbvS2pU6nTIopTQHGAy8BWwGnLu0ximl21JKO6SUdth6rb6fvso1zPMPP8WA/XdcbN92B+202FTKsnwwYQq3HH85Vx90Hs//9mmmT3q/OcpUa9WmDe0Hn0rt+Oeom/AisXZP2nTpQYdjL6DDSZcRnbvR4ejzoaILALHOhrTb53iqfnvzYvPfaf6swpOFc6mb8BJt1uv9sUvVjf8XbTf7/KroVatVaogvmnY5EHgopeRXyStZz97rNzzfet8deH/ClIbtDmt1pO+OWzH2z2NKOlfnHsW/XBEMOvNQ/jnyf1dusWrV2u1zPPUzp1L7YuG+STOmsPC2c6m8axiVdw0jzfuQylHDYcEcYq1utB/8Tar/dBdp1gcfnaSs3Ufz3WXtaLPxVtTPKNzT0XXdhmZt+2xL/YdTV1nfWqNS58QfjYjxwELgtIjoCVQu5zVaiuNvOIvNvrgVnbutxY+euYk//PSXbLXntqzbpxepvp6Z707nwWF3NLTfZr+BvPbky1QvrFrueZ598K9sf/Au7HrcIABe/tNz/Ouhv63K7iljbXr1pWyrnaifNpm2x5wPQPU/H6b+rf98YvvyHQcTHTrRbq+jARqWEkZFF9of9M3iSdtSO/456icV5svLdzmUNt3Wg5RIc2dS/ZeRzd+xVqzkJYYR0R2YnVKqi4gKoEtKablvoS4x1OrKJYZanZW6xLCkkXhElAPHArtFBMDfgVtXuDpJ0kpR6nTKLUA5cHNx+7jivm80R1GSpNKUGuJfSCkNaLT9RET8uzkKkiSVrtTVKXUR0bBWMCL6AHXNU5IkqVSljsTPBf4aEW8Wt3sDJzZLRZKkkpU6Ev8nMAKoB2YWnz/TXEVJkkpTaoj/AtgUuBS4EegD3NtcRUmSSlPqdMrWKaWtGm3/NSJeaY6CJEmlK3Uk/kJEfHHRRkTsCJT2M+CSpGZT6kh8e+DpiHi7uL0x8FpEjAVSSmmbZqlOkrRMpYb4/s1ahSRphZQU4imlSc1diCSp6fzv2SQpY4a4JGXMEJekjBnikpQxQ1ySMmaIS1LGDHFJypghLkkZM8QlKWOGuCRlzBCXpIwZ4pKUMUNckjJmiEtSxgxxScqYIS5JGTPEJSljhrgkZcwQl6SMGeKSlDFDXJIyZohLUsYMcUnKmCEuSRkzxCUpY4a4JGXMEJekjBnikpQxQ1ySMmaIS1LGDHFJypghLkkZM8QlKWOGuCRlzBCXpIwZ4pKUMUNckjJmiEtSxiKl1NI1qAki4pSU0m0tXYe0JO/NluFIPD+ntHQB0lJ4b7YAQ1ySMmaIS1LGDPH8OOeo1ZX3Zgvwi01JypgjcUnKmCEuSRkzxCUpY4a4JGXMEF+NRETviHg1Im6PiHER8XhEdIyIvhHxx4h4PiKejIh+xfZ9I+LZiBgbEcMjYl5L90GtV/H+HB8RI4v36S8joiIi9o6IF4v34V0R0b7Y/oqIeCUiXo6Iq1u6/tbKEF/9bA7clFLqD8wCvkJh6dZZKaXtgaHAzcW21wPXp5Q+B0xuiWK1xtkSuDml9FlgDnAOcDdwZPE+LANOi4gewKFA/5TSNsDwFqq31TPEVz8TU0ovFZ8/D/QGdgYeioiXgBHABsXjOwEPFZ+PWpVFao31Tkrpn8Xn9wF7U7hnXy/uuwfYDZgNVAJ3RsRhwIJVXukaoqylC9DHVDV6XgesB8xKKW3bQvVIjS35gyWzgB4fa5RSbUQMpBDyXwXOBPZq/vLWPI7EV39zgIkRcThAFAwoHnuWwnQLwFEtUZzWOBtHxE7F50cDY4DeEbFZcd9xwN8jojOwdkrpMeA7wICPn0orgyGeh2OAkyPi38A44JDi/rOBcyLiZWAzCh9hpeb0GnBGRLwKdAN+CpxIYbpvLFAP3AqsBTxavDefojB3rmbgj91nLCIqgIUppRQRRwFfSykdsrzXSSsiInoDj6aUtm7hUtSIc+J52x74WUQEhbnJk1q4HkmrmCNxScqYc+KSlDFDXJIyZohLUsYMcUnKmCEuSRn7f/jEyqleQe0kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x158d62320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = pred.argmax(axis=-1)\n",
    "y_pred = le.inverse_transform(y_pred)\n",
    "\n",
    "print(\"Precision: {0:6.2f}\".format(precision_score(y_test, y_pred, average='macro')))\n",
    "print(\"Recall: {0:6.2f}\".format(recall_score(y_test, y_pred, average='macro')))\n",
    "print(\"F1-measure: {0:6.2f}\".format(f1_score(y_test, y_pred, average='macro')))\n",
    "print(\"Accuracy: {0:6.2f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "sns.heatmap(data=confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cbar=False, xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
